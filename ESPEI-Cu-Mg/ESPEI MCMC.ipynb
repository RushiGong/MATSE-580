{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESPEI\n",
    "\n",
    "### Extensible Self-optimizating Phase Equilibria Infrastructure\n",
    "\n",
    "Documentation for internal and external APIs can be found at https://espei.org\n",
    "\n",
    "Solutions to this notebook can be found at https://github.com/materialsgenomefoundation/2020-workshop-material\n",
    "\n",
    "## Markov Chain Monte Carlo (MCMC)\n",
    "\n",
    "### Running MCMC\n",
    "\n",
    "The most minimal MCMC settings file that could be used for ESPEI only requires setting the source of the database (i.e. the database from parameter selection) and the number of iterations.\n",
    "\n",
    "```yaml\n",
    "system:\n",
    "  phase_models: phases.json\n",
    "  datasets: input-data/run\n",
    "output:\n",
    "  output_db:  mcmc.tdb\n",
    "  verbosity:  2\n",
    "mcmc:\n",
    "  iterations: 100\n",
    "  input_db: dft-aicc_penalty.tdb\n",
    "```\n",
    "\n",
    "By default, ESPEI will run in parallel using the `dask` package. If you try to run this locally, you may need to do an [extra step to configure dask](https://espei.org/en/latest/installation.html#configuration).\n",
    "\n",
    "However, since we are using limited and shared cloud resources, we will make some compromises in terms of accuracy and storage. The settings we'll use for running MCMC simulations are as follows (saved as `mcmc_settings.yaml`):\n",
    "\n",
    "All MCMC options are explained in [ESPEI's YAML settings file documentation](https://espei.org/en/latest/writing_input.html#mcmc). Compared to parameter generation, the options are more extensive and worth being familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import distributed\n",
    "dask.config.set({'distributed.scheduler.work-stealing': False})\n",
    "\n",
    "import yaml\n",
    "from espei import run_espei\n",
    "from pycalphad import Database, binplot, equilibrium, variables as v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mcmc_settings.yaml') as fp:\n",
    "    mcmc_settings = yaml.safe_load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll run the MCMC simulation for just two iterations. The outputs are the database which has the most optimal parameters of all samples and an `emcee.EnsembleSampler` object that contains the trace (contains samples of the parameters for every chain and iteration) and the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:espei version       0.7.8\n",
      "INFO:root:If you use ESPEI for work presented in a publication, we ask that you cite the following paper:\n",
      "    B. Bocklund, R. Otis, A. Egorov, A. Obaied, I. Roslyakova, Z.-K. Liu, ESPEI for efficient thermodynamic database development, modification, and uncertainty quantification: application to Cu-Mg, MRS Commun. (2019) 1-10. doi:10.1557/mrc.2019.59.\n",
      "TRACE:root:Loading and checking datasets.\n",
      "TRACE:root:Finished checking datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single phase datasets are present, but there are no specified `excluded_model_contributions` keys present. 'idmix' exclusion will be added automatically for backwards compatibility, but this will go away in ESPEI v0.8. If you want ideal mixing contributions to be excluded, see the documentation for building datasets: http://espei.org/en/latest/input_data.html\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The parameter 'work-stealing' is on in dask. Enabling this parameter causes some instability. Set 'distributed.scheduler.work-stealing: False' in your dask configuration. Configuration files on this machine are:\n[] (latter files have priority).\nSee the example at http://espei.org/en/latest/installation.html#configuration for more.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f139e66f8a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdbf_mcmc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_espei\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcmc_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfs/group/dml129/default/matse_580/conda_env/lib/python3.7/site-packages/espei/espei_script.py\u001b[0m in \u001b[0;36mrun_espei\u001b[0;34m(run_settings)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# scheduler setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmcmc_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scheduler'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0m_raise_dask_work_stealing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# check for work-stealing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mdistributed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLocalCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mcores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcmc_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cores'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/group/dml129/default/matse_580/conda_env/lib/python3.7/site-packages/espei/espei_script.py\u001b[0m in \u001b[0;36m_raise_dask_work_stealing\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;34m\"Set 'distributed.scheduler.work-stealing: False' in your dask configuration. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m\"Configuration files on this machine are:\\n{} (latter files have priority).\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \"See the example at http://espei.org/en/latest/installation.html#configuration for more.\".format(get_dask_config_paths()))\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The parameter 'work-stealing' is on in dask. Enabling this parameter causes some instability. Set 'distributed.scheduler.work-stealing: False' in your dask configuration. Configuration files on this machine are:\n[] (latter files have priority).\nSee the example at http://espei.org/en/latest/installation.html#configuration for more."
     ]
    }
   ],
   "source": [
    "dbf_mcmc, sampler = run_espei(mcmc_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the key output from the sampler are the trace (`emcee` calls this the \"chain\") and the log-probability (lnprob). The trace has the shape `(number of chains, number of iterations, number of parameters)`. The log-probability has the shape  `(number of chains, number of iterations)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = sampler.chain\n",
    "lnprob = sampler.lnprobability\n",
    "\n",
    "print(f\"Trace shape:           {trace.shape}\")\n",
    "print(f\"Log-probability shape: {lnprob.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the MCMC simulation complete, we can see what the phase diagram looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espei.plot import dataplot\n",
    "from espei.datasets import recursive_glob, load_datasets\n",
    "\n",
    "# load our JSON datasets into an in-memory database\n",
    "datasets = load_datasets(recursive_glob('input-data', '*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comps = ['CU', 'MG', 'VA']\n",
    "phases = ['LIQUID', 'FCC_A1', 'HCP_A3', 'CUMG2', 'LAVES_C15']\n",
    "conds = {v.P: 101325, v.T: (300, 1500, 10), v.X('MG'): (0, 1, 0.01)}\n",
    "ax = binplot(dbf_mcmc, comps, phases, conds)\n",
    "dataplot(comps, phases, conds, datasets, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After just three MCMC iterations through 24 chains, the phase diagram shows a significant improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated MCMC analysis\n",
    "\n",
    "Typically, a fully converged MCMC simulation with enough samples to do uncertainty quantification will require a few hundred to a few thousand calculations. \n",
    "\n",
    "\n",
    "Since performing an MCMC simulation for a significant period of time is not possible in this workshop, an existing pre-computed trace and log-probability are loaded that took 2000 iterations of sampling 24 chains for a total of 48,000 samples in parameter space. These 48,000 samples took 3.5 hours to run across 6 cores on a 2015 MacBook Pro (2.2 GHz Intel i7).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from espei.analysis import truncate_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = np.load('trace.npy')\n",
    "lnprob = np.load('lnprob.npy')\n",
    "\n",
    "trace, lnprob = truncate_arrays(trace, lnprob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing convergence of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(lnprob.T)\n",
    "plt.title('Log-probability convergence\\n(1 line = 1 chain)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log-probability')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lnprob.T)\n",
    "plt.title('Zoomed Log-probability convergence\\n(1 line = 1 chain)')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Log-probability')\n",
    "plt.ylim(-4000, -2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing change in a particular parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of parameter of interest within the chain\n",
    "# could be looped to produce figures for all parameters\n",
    "parameter_idx = 5\n",
    "\n",
    "num_chains = trace.shape[0]\n",
    "ax = plt.figure().gca()\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Parameter value')\n",
    "ax.plot(trace[..., parameter_idx].T)\n",
    "ax.set_title('Parameter Convergence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the optimal set of parameters and plotting the phase diagram\n",
    "\n",
    "An MCMC simulation has many samples, but we are still likely interested in getting the set of parameters that's the best point estimate of the data.\n",
    "\n",
    "ESPEI provides an `optimal_parameters` function that will extract the parameter set with the highest log-probability, which can be used to update the symbols that we fit in the database ($ \\mathrm{VV0001} $, ...).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from espei.utils import database_symbols_to_fit, optimal_parameters\n",
    "import copy\n",
    "\n",
    "# make an in-memory copy of the database because updating the\n",
    "# symbols with the optimal solutions will erase the old ones\n",
    "dbf_opt = copy.deepcopy(dbf_mcmc)\n",
    "\n",
    "# Find the optimal parameters and replace the values in the symbols dictionary\n",
    "opt_params = dict(zip(database_symbols_to_fit(dbf_opt), optimal_parameters(trace, lnprob)))\n",
    "dbf_opt.symbols.update(opt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the phase diagram\n",
    "\n",
    "ax = binplot(dbf_opt, comps, phases, conds)\n",
    "dataplot(comps, phases, conds, datasets, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge yourself\n",
    "\n",
    "Test your understanding by \n",
    "\n",
    "* Changing the relative weights of the types of data (`ZPF`, `SM` or try adding `HM`) to see what happens to the phase diagram after a few iterations.\n",
    "* Change the verbosity in the MCMC settings YAML files to a higher or lower number and investigate the output. **Warning: a lot of output can be generated for verbosity level of 3, so it is best to try only 1-2 iterations**.\n",
    "* Pick other parameter indices and try to match up the convergence of the log-probability with the changes in local minima for a parameter plotted across a number of iterations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
